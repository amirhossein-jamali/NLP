{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# **CharLevel_LSTM_LM_Assignment**\n",
    "**Name:** Amirhossein Jamali\n",
    "\n",
    "**GitHub repository:** https://github.com/jamir91/NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hazm import Normalizer, Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    n_tokens = 0\n",
    "\n",
    "    frequencies = {}\n",
    "    charToIndex = {}\n",
    "    indexToChar = {}\n",
    "    index = 0\n",
    "\n",
    "    def __init__(self, address='../data/'):\n",
    "        # self.frequencies = self.open_dic()\n",
    "        self.read_data(address)\n",
    "        # self.plot_distribution()\n",
    "        self.clean_text()\n",
    "        # self.count_words()\n",
    "        # self.map_word_index()\n",
    "\n",
    "\n",
    "    def read_data(self, address):\n",
    "        self.train_data = pd.read_csv(address + 'train.csv', sep='\\t', error_bad_lines= False , encoding= 'utf-8')\n",
    "        self.train_data.drop(self.train_data[self.train_data.category=='category'].index, axis=0, inplace=True)\n",
    "        self.train_data.dropna(subset=['text'], inplace=True)\n",
    "        self.test_data = pd.read_csv(address + 'test.csv', sep='\\t', error_bad_lines= False , encoding= 'utf-8')\n",
    "        self.test_data.drop(self.test_data[self.test_data.category=='category'].index, axis=0, inplace=True)\n",
    "        self.test_data.dropna(subset=['text'], inplace=True)\n",
    "#         print(self.stop_words)\n",
    "#         print('-------------------------------------------------------------')\n",
    "#         print(self.train_data.info())\n",
    "#         print('-------------------------------------------------------------')\n",
    "#         print(self.test_data.info())\n",
    "\n",
    "    def remove_none_alpha(self, d):\n",
    "        persian_chars = u'\\u200c ‌آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی۰۱۲۳۴۵۶۷۸۹.؟?0123456789'\n",
    "        dd = ''\n",
    "        d = d.replace('\\n', ' ')\n",
    "        for c in d:\n",
    "            if c in persian_chars:\n",
    "                dd += c\n",
    "\n",
    "        return dd\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_digits(d):\n",
    "        persian_digits = u'0123456789۱۲۳۴۵۶۷۸۹۰'\n",
    "        for c in d:\n",
    "            if c in persian_digits:\n",
    "                d = d.replace(c, 'N')\n",
    "        while 'NN' in d:\n",
    "            d = d.replace('NN', 'N')\n",
    "        while 'N.N' in d:\n",
    "            d = d.replace('N.N', 'N')\n",
    "\n",
    "        return d\n",
    "\n",
    "    @staticmethod\n",
    "    def char_tokenize(news):\n",
    "\n",
    "        return [char for char in news]\n",
    "\n",
    "    def clean_text(self):\n",
    "        self.train_data.drop(self.train_data[self.train_data.category=='category'].index, axis=0, inplace=True)\n",
    "        self.train_data.dropna(subset=['text'], inplace=True)\n",
    "        self.train_data = self.train_data[['text']]\n",
    "#         self.train_data = self.train_data[['category', 'text']]\n",
    "        normalizer = Normalizer()\n",
    "        self.train_data['text'] = self.train_data['text'].apply(normalizer.normalize)\n",
    "        self.train_data['text'] = self.train_data['text'].apply(self.remove_none_alpha)\n",
    "        self.train_data['text'] = self.train_data['text'].apply(self.replace_digits)\n",
    "        self.train_data['text'] = self.train_data['text'].apply(self.char_tokenize)\n",
    "#         self.train_data['text'] = self.train_data['text'].apply(self.df_stemmer)\n",
    "        self.train_data.reset_index(drop=True, inplace=True)\n",
    "        self.train_data.to_pickle('train_dataframe')\n",
    "#         print(self.train_data['text'][1])\n",
    "\n",
    "        self.test_data.drop(self.test_data[self.test_data.category=='category'].index, axis=0, inplace=True)\n",
    "        self.test_data.dropna(subset=['text'], inplace=True)\n",
    "        self.test_data = self.test_data[['text']]\n",
    "#         self.test_data = self.test_data[['category', 'text']]\n",
    "        self.test_data['text'] = self.test_data['text'].apply(normalizer.normalize)\n",
    "        self.test_data['text'] = self.test_data['text'].apply(self.remove_none_alpha)\n",
    "        self.test_data['text'] = self.test_data['text'].apply(self.replace_digits)\n",
    "        self.test_data['text'] = self.test_data['text'].apply(self.char_tokenize)\n",
    "#         self.test_data['text'] = self.test_data['text'].apply(self.df_stemmer)\n",
    "        self.test_data.reset_index(drop=True, inplace=True)\n",
    "        self.test_data.to_pickle('test_dataframe')\n",
    "#         print(self.test_data['text'][1])\n",
    "\n",
    "    def save_dict(self, d, n=200):\n",
    "        f_out = open(\"frequent.txt\", \"w\", encoding=\"utf-8\")\n",
    "        for item, count in list(d.items())[:n]:\n",
    "            f_out.write(f'{item}, {count}\\n')\n",
    "\n",
    "    def freq(self, tokens):\n",
    "        for t in tokens:\n",
    "            self.n_tokens += 1\n",
    "            if t in self.frequencies:\n",
    "                self.frequencies[t] += 1\n",
    "            else:\n",
    "                self.frequencies[t] = 1\n",
    "\n",
    "    def count_words(self):\n",
    "        self.train_data['text'].map(self.freq)\n",
    "        self.frequencies = dict(sorted(self.frequencies.items(), key=lambda item: item[1], reverse=True))\n",
    "        self.save_dict(self.frequencies)\n",
    "\n",
    "    def map_word_index(self):\n",
    "        self.wordToIndex = {k: v + 1 for v, k in enumerate(list(self.frequencies.keys()))}\n",
    "        self.indexToWord = {v + 1: k for v, k in enumerate(list(self.frequencies.keys()))}\n",
    "\n",
    "    def tokenize(self, tokens):\n",
    "        return [self.wordToIndex[i] for i in tokens]\n",
    "\n",
    "    def open_dic(self):\n",
    "        d = {}\n",
    "        with open(\"frequent_list.txt\", encoding=\"utf8\") as f:\n",
    "            for line in f:\n",
    "                (key, val) = line.split(',')\n",
    "                d[key] = val\n",
    "\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    d = DataPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a = d.train_data['text'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " به گزارش خبرنگار رادیو تلویزیون باشگاه خبرنگاران مجموعه تلویزیونی مدرس به کارگردانی هوشنگ توکلی و تهیه کنندگی اسماعیل شنگله از شبکه یک سیما در سال N پخش شد. این اثر که داستان زندگی سید حسن مدرس را به تصویر می‌کشید به برهه‌ای از زندگی این شهید بزرگوار از ورود به تهران تا کاندیدا شدن ایشان در مجلس شورای اسلامی و درگیری با رضا شاه و کشته شدن ایشان به دستور رضا شاه پرداخت. این سریال به دلیل بازی درخشان و تحسین برانگیز خسرو شکیبایی در نقش مدرس در یادها ماندگار شد. خسرو شکیبایی بی شک یکی از ماندگار‌ترین نقش‌هایش را در این سریال به تصویر کشید. از جمله این‌که وی در این سریال مونولوگ‌های N دقیقه‌ای را حتی بدون یک بار کات دادن بازی کرد و با قدرت بیان فوق العاده‌اش قدرت و استواری مدرس در برابر رضا شاه را به خوبی به تصویر کشید. تا کنون نقش شهید مدرس را بازیگرانی چون زنده یاد هادی اسلامی در سریال تلویزیونی مرغ حق و حسین محجوب در اثر عمارت فرنگی ایفا کرده‌اند که آن‌ها هم توانسته‌اند به خوبی از پس نقش برآیند. هوشنگ توکلی کارگردان سریال تلویزیونی مدرس در گفتگو با خبرنگار ما در خصوص ساخت این سریال گفت ‌ دغدغه‌ی اهالی هنر پس از انقلاب ساخت چنین آثاری بود. وی افزود یکی از شخصیت‌های مهمی که تا کنون در مجلس حضور داشته شهید مدرس بود ‌ به همین دلیل ما در آن زمان به این شخصیت پرداختیم و مدیر شبکه یک و مدیر گروه سریال آن زمان بر روی این مقوله بسیار حساس بودند. توکلی عنوان کرد این اثر یکی از پر مخاطب‌ترین سریال‌های تلویزیونی آن دوران بود که N درصد بیننده داشت. این کارگردان در خصوص بازی زنده یاد خسرو شکیبایی در نقش مدرس بیان کرد شکیبایی یکی از بازیگران با سابقه و با تجربه بود و علاقه خاصی به حرفه‌اش داشت و برای نقش شهید مدرس هم وقت و انرژی زیادی را صرف کرد. وی ادامه داد شکیبایی این نقش را به نام خودش ثبت کرد و پس از پیشنهاد این کار نقش را چشم بسته پذیرفت. البته همه‌ی بازیگران این اثر جز بهترین‌های دهه‌ی N بودند. انتهای پیام اس"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i,end= \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , ح, و, ز, ه,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , ح, و, ز, ه,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97017</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , گ, ر, و, ه,  , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97018</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97019</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97020</th>\n",
       "      <td>[ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97021</th>\n",
       "      <td>[ , ب, ر, ن, ا, م, ه,  , ر, ق, ا, ب, ت, ‌, ه, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97022 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text\n",
       "0      [ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...\n",
       "1      [ , ب, ه,  , گ, ز, ا, ر, ش,  , ح, و, ز, ه,  , ...\n",
       "2      [ , ب, ه,  , گ, ز, ا, ر, ش,  , ح, و, ز, ه,  , ...\n",
       "3      [ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...\n",
       "4      [ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...\n",
       "...                                                  ...\n",
       "97017  [ , ب, ه,  , گ, ز, ا, ر, ش,  , گ, ر, و, ه,  , ...\n",
       "97018  [ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...\n",
       "97019  [ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...\n",
       "97020  [ , ب, ه,  , گ, ز, ا, ر, ش,  , خ, ب, ر, ن, گ, ...\n",
       "97021  [ , ب, ر, ن, ا, م, ه,  , ر, ق, ا, ب, ت, ‌, ه, ...\n",
       "\n",
       "[97022 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.train_data[['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}